{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic (Gaussian likelihood) GP regression model\n",
    "\n",
    "\n",
    "This notebook shows the different steps for creating and using a standard GP regression model, including:\n",
    "  - reading and formatting data\n",
    "  - choosing a kernel function\n",
    "  - choosing a mean function (optional)\n",
    "  - creating the model\n",
    "  - viewing, getting, and setting model parameters\n",
    "  - optimising the model parameters\n",
    "  - making predictions\n",
    "  \n",
    "We focus here on the implementation of the models in GPflow; for more intuition on these models, see [A Practical Guide to Gaussian Processes](https://drafts.distill.pub/gp/).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T08:59:50.141046Z",
     "start_time": "2018-06-19T08:59:49.132677Z"
    }
   },
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from gpflow.utilities import print_summary\n",
    "\n",
    "# The lines below are specific to the notebook format\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 6)\n",
    "plt = matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` and `Y` denote the input and output values. **NOTE:** `X` and `Y` must be two-dimensional NumPy arrays, $N \\times 1$ or $N \\times D$, where $D$ is the number of input dimensions/features, with the same number of rows as $N$ (one for each data point):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.genfromtxt('data/regression_1D.csv', delimiter=',')\n",
    "X = data[:, 0].reshape(-1, 1)\n",
    "Y = data[:, 1].reshape(-1, 1)\n",
    "\n",
    "plt.plot(X, Y, 'kx', mew=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider the following probabilistic model:\n",
    "$$ Y_i = f(X_i) + \\varepsilon_i , $$\n",
    "where $f \\sim \\mathcal{GP}(\\mu(\\cdot), k(\\cdot, \\cdot'))$, and $\\varepsilon \\sim \\mathcal{N}(0, \\tau^2 I)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a kernel \n",
    "Several kernels (covariance functions) are implemented in GPflow. You can easily combine them to create new ones (see [Manipulating kernels](../advanced/kernels.ipynb)). You can also implement new covariance functions, as shown in the [Kernel design](../tailor/kernel_design.ipynb) notebook. Here, we will use a simple one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = gpflow.kernels.Matern52()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more advanced kernels see the [advanced kernel notebook](../advanced/kernels.ipynb) (including kernels defined on subspaces). A summary of the kernel can be obtained by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                  class      transform    trainable    shape    dtype      value\n",
      "--------------------  ---------  -----------  -----------  -------  -------  -------\n",
      "Matern52.variance     Parameter  Softplus     True         ()       float64        1\n",
      "Matern52.lengthscale  Parameter  Softplus     True         ()       float64        1\n"
     ]
    }
   ],
   "source": [
    "print_summary(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Matern 5/2 kernel has two parameters: `lengthscale`, which encodes the \"wiggliness\" of the GP, and `variance`, which tunes the amplitude. They are both set to 1.0 as the default value. For more details on the meaning of the other columns, see [Manipulating kernels](../advanced/kernels.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a mean function (optional)\n",
    "It is common to choose $\\mu = 0$, which is the GPflow default. \n",
    "\n",
    "However, if there is a clear pattern (such as a mean value of `Y` that is far away from 0, or a linear trend in the data), mean functions can  be beneficial. Some simple ones are provided in the `gpflow.mean_functions` module.\n",
    "\n",
    "Here's how to define a linear mean function:\n",
    "\n",
    "`meanf = gpflow.mean_functions.Linear()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a model\n",
    "A GPflow model is created by instantiating one of the GPflow model classes, in this case GPR. We'll make a kernel `k` and instantiate a GPR object using the generated data and the kernel. We'll also set the variance of the likelihood to a sensible initial guess. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T08:59:50.402776Z",
     "start_time": "2018-06-19T08:59:50.292900Z"
    }
   },
   "outputs": [],
   "source": [
    "m = gpflow.models.GPR(kernel=k, mean_function=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary of the model can be obtained by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                     class      transform    trainable    shape    dtype      value\n",
      "-----------------------  ---------  -----------  -----------  -------  -------  -------\n",
      "GPR.kernel.variance      Parameter  Softplus     True         ()       float64        1\n",
      "GPR.kernel.lengthscale   Parameter  Softplus     True         ()       float64        1\n",
      "GPR.likelihood.variance  Parameter  Softplus     True         ()       float64        1\n"
     ]
    }
   ],
   "source": [
    "print_summary(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two lines correspond to the kernel parameters, and the third one gives the likelihood parameter (the noise variance $\\tau^2$ in our model).\n",
    "\n",
    "You can access those values and manually set them to sensible initial guesses. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.likelihood.variance.assign(0.01)\n",
    "m.kernel.lengthscale.assign(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise the model parameters\n",
    "\n",
    "To obtain meaningful predictions, you need to tune the model parameters (that is, the parameters of the kernel, the likelihood, and the mean function if applicable) to the data at hand. \n",
    "\n",
    "There are several optimisers available in GPflow. Here we use the `Scipy` optimizer, which by default implements the L-BFGS-B algorithm. (You can select other algorithms by using the `method=` keyword argument to its `minimize` method; see [the SciPy documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) for details of available options.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = gpflow.optimizers.Scipy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to minimize the negative log marginal likelihood, we create a closure to be passed to the optimizer. We also need to specify the variables to train with `m.trainable_variables`, and the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                     class      transform    trainable    shape    dtype         value\n",
      "-----------------------  ---------  -----------  -----------  -------  -------  ----------\n",
      "GPR.kernel.variance      Parameter  Softplus     True         ()       float64  7.96571\n",
      "GPR.kernel.lengthscale   Parameter  Softplus     True         ()       float64  0.212416\n",
      "GPR.likelihood.variance  Parameter  Softplus     True         ()       float64  0.00575949\n"
     ]
    }
   ],
   "source": [
    "def objective_closure():\n",
    "    return m.objective((X, Y))\n",
    "\n",
    "opt_logs = opt.minimize(objective_closure,\n",
    "                        m.trainable_variables,\n",
    "                        options=dict(maxiter=100))\n",
    "print_summary(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the value column has changed.\n",
    "\n",
    "The local optimum found by Maximum Likelihood might not be the one you want (for example, it might be overfitting or oversmooth). This depends on the initial values of the hyperparameters, and is specific to each dataset. As an alternative to Maximum Likelihood, [Markov Chain Monte Carlo (MCMC)](../advanced/mcmc.ipynb) is also available.\n",
    "\n",
    "## Make predictions\n",
    "\n",
    "We can now use the model to make some predictions at the new points `Xnew`. You might be interested in predicting two different quantities: the latent function values `f(Xnew)` (the denoised signal), or the values of new observations `y(Xnew)` (signal + noise). Because we are dealing with Gaussian probabilistic models, the predictions typically produce a mean and variance as output. Alternatively, you can obtain samples of `f(Xnew)` or the log density of the new data points `(Xnew, Ynew)`.\n",
    "\n",
    "GPflow models have several prediction methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `m.predict_f` returns the mean and marginal variance of $f$ at the points `Xnew`. \n",
    "\n",
    " - `m.predict_f` with argument `full_cov=True` returns the mean and the full covariance matrix of $f$ at the points `Xnew`.\n",
    "\n",
    " - `m.predict_f_samples` returns samples of the latent function.\n",
    "\n",
    " - `m.predict_y` returns the mean and variance of a new data point (that is, it includes the noise variance).\n",
    "\n",
    " - `m.predict_log_density` returns the log density of the observations `Ynew` at `Xnew`.\n",
    " \n",
    "We use `predict_f` and `predict_f_samples` to plot 95% confidence intervals and samples from the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T08:59:50.640000Z",
     "start_time": "2018-06-19T08:59:50.404378Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPR' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1628693ebd9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## predict mean and variance of latent GP at test points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m## generate 10 samples from posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/GPflow/gpflow/models/gpr.py\u001b[0m in \u001b[0;36mpredict_f\u001b[0;34m(self, predict_at, full_cov, full_output_cov)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mwhere\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mare\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mGP\u001b[0m \u001b[0mat\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0mare\u001b[0m \u001b[0mnoisy\u001b[0m \u001b[0mobservations\u001b[0m \u001b[0mat\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_data\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPR' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "## generate test points for prediction\n",
    "xx = np.linspace(-0.1, 1.1, 100).reshape(100, 1)  # test points must be of shape (N, D)\n",
    "\n",
    "## predict mean and variance of latent GP at test points\n",
    "mean, var = m.predict_f(xx)\n",
    "\n",
    "## generate 10 samples from posterior\n",
    "samples = m.predict_f_samples(xx, 10)  # shape (10, 100, 1)\n",
    "\n",
    "## plot \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(X, Y, 'kx', mew=2)\n",
    "plt.plot(xx, mean, 'C0', lw=2)\n",
    "plt.fill_between(xx[:,0],\n",
    "                 mean[:,0] - 1.96 * np.sqrt(var[:,0]),\n",
    "                 mean[:,0] + 1.96 * np.sqrt(var[:,0]),\n",
    "                 color='C0', alpha=0.2)\n",
    "\n",
    "plt.plot(xx, samples[:, :, 0].numpy().T, 'C0', linewidth=.5)\n",
    "plt.xlim(-0.1, 1.1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP regression in higher dimensions\n",
    "\n",
    "Very little changes when the input space has more than one dimension. By default, the `lengthscale` is an isotropic (scalar) parameter. It is generally recommended that you allow to tune a different lengthscale for each dimension (Automatic Relevance Determination, ARD): simply initialise `lengthscale` with an array of length $D$ corresponding to the input dimension of `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "  - [Stochastic Variational Inference for scalability with SVGP](../advanced/gps_for_big_data.ipynb) for cases where there are a large number of observations.\n",
    "  - [Ordinal regression](../advanced/ordinal_regression.ipynb) if the data is ordinal.\n",
    "  - [Multi-output models and coregionalisation](../advanced/coregionalisation.ipynb) if `Y` is multidimensional."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
