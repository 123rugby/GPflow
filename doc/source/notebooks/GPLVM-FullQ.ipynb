{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian GPLVM with full rank covariance\n",
    "--\n",
    "This notebook shows the difference between a full rank and a diagonal variational distribution over the latent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import GPflow\n",
    "from GPflow import ekernels\n",
    "from GPflow import kernels\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import pods\n",
    "pods.datasets.overide_manual_authorize = True  # dont ask to authorize\n",
    "np.random.seed(42)\n",
    "GPflow.settings.numerics.quadrature = 'error'  # throw error if quadrature is used for kernel expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Install the oil dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points X Number of dimensions (100, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bishop, C. M. and G. D. James (1993). Analysis of multiphase flows using dual-energy gamma densitometry and neural networks. Nuclear Instruments and Methods in Physics Research A327, 580-593'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pods.datasets.oil_100()\n",
    "Y = data['X']\n",
    "print('Number of points X Number of dimensions', Y.shape)\n",
    "data['citation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction\n",
    "Create Bayesian GPLVM model using additive kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = 3\n",
    "M = 20  # number of inducing pts\n",
    "N = Y.shape[0]\n",
    "X_mean = GPflow.gplvm.PCA_reduce(Y, Q) # Initialise via PCA\n",
    "Z = np.random.permutation(X_mean.copy())[:M]\n",
    "kerngen = lambda: ekernels.RBF(Q, ARD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_std_full = np.array([0.1**0.5*np.eye(Q) for _ in range(N)])\n",
    "mfull = GPflow.gplvm.BayesianGPLVM(X_mean=X_mean.copy(), X_std=X_std_full, Y=Y,\n",
    "                                kern=kerngen(), M=M, Z=Z.copy())\n",
    "mfull.likelihood.variance = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the new full q(x) has the same value when diagonal is used\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "mfull_ll = list()\n",
    "mdiag_ll = list()\n",
    "def evalDiagBound(free_state):\n",
    "    ''' Callback for diag model optimizer. Also evaluates bound for full model '''    \n",
    "    oldstate = mdiag.get_free_state()\n",
    "    mdiag.set_state(free_state)\n",
    "    mdiag_ll.append(mdiag.compute_log_likelihood())\n",
    "    d = mdiag.get_parameter_dict()\n",
    "    # replace diagonal with full covariance\n",
    "    X_std_fullmodel = np.array([np.diag(mdiag.X_std.value[i,:]) for i in range(N)])\n",
    "    d['model.X_std'] = X_std_fullmodel\n",
    "    mfull.set_parameter_dict(d)\n",
    "    mfull_ll.append(mfull.compute_log_likelihood())\n",
    "    mdiag.set_state(oldstate)  # and restore\n",
    "\n",
    "mdiag = GPflow.gplvm.BayesianGPLVM(X_mean=X_mean.copy(), X_std=0.1**0.5*np.ones((N, Q)), Y=Y,\n",
    "                                kern=kerngen(), M=M, Z=Z.copy())\n",
    "mdiag.likelihood.variance = 0.01\n",
    "mdiag.optimize(disp=True, maxiter=100, callback=evalDiagBound)\n",
    "\n",
    "assert np.allclose(np.array(mfull_ll), np.array(mdiag_ll)), 'Loglikelihood should be same for same q(x)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfull_ll = list()\n",
    "mdiag_ll = list()\n",
    "def evalFullBound(free_state):\n",
    "    ''' Callback for full model optimizer. Also evaluate bound for diagonal model '''\n",
    "    oldstate = mfull.get_free_state()\n",
    "    mfull.set_state(free_state)\n",
    "    mfull_ll.append(mfull.compute_log_likelihood())\n",
    "    d = mfull.get_parameter_dict()\n",
    "    # replace full covariance with diagonal\n",
    "    X_std_diagmodel = np.array([np.diag(mfull.X_std.value[i,:,:]) for i in range(N)])\n",
    "    d['model.X_std'] = X_std_diagmodel\n",
    "    mdiag.set_parameter_dict(d)\n",
    "    mdiag_ll.append(mdiag.compute_log_likelihood())\n",
    "    mfull.set_state(oldstate)  # and restore\n",
    "    \n",
    "mfull.optimize(disp=True, maxiter=100, callback=evalFullBound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(7,7))\n",
    "ax.plot(np.array(mfull_ll), label='full')\n",
    "ax.plot(np.array(mdiag_ll), label='diag')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Log likelihood bound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mfull.get_free_state().shape, mdiag.get_free_state().shape)\n",
    "print(mfull.get_parameter_dict().keys(), mdiag.get_parameter_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mfull.X_std.value.shape, mdiag.X_std.value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_std_fullmodel = np.array([np.diag(mdiag.X_std.value[i,:]) for i in range(N)])\n",
    "print(X_std_fullmodel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mdiag.kern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mfull.kern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and sensitivity to input\n",
    "Sensitivity is a measure of the importance of each latent dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colours = ['b', 'y']\n",
    "labels = ['diag', 'full']\n",
    "inputIndices = list()\n",
    "for i, m in enumerate([mdiag, mfull]):\n",
    "    kern = m.kern\n",
    "    sens = np.sqrt(kern.variance.value)/kern.lengthscales.value\n",
    "    inputIndices.append(np.argsort(sens)[::-1][:2])\n",
    "    print(sens)\n",
    "    #fig, ax = plt.subplots()\n",
    "    plt.bar(np.arange(len(kern.lengthscales.value)) + 0.1 * i , sens, 0.1, color=colours[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.title('Sensitivity to latent inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputIndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting vs PCA\n",
    "We see that using the 2 more relevant dimensions, the Bayesian GPLVM is able to seperate the\n",
    "three classes while PCA cannot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "def linearSep(X, lbl):\n",
    "    ''' function to compute linear separability '''\n",
    "    return accuracy_score(lbl, svm.SVC(kernel='linear').fit(X, lbl).predict(X))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XPCAplot = GPflow.gplvm.PCA_reduce(data['X'], 2)\n",
    "f, ax = plt.subplots(1,3, figsize=(14,6))\n",
    "labels=data['Y'].argmax(axis=1)\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(np.unique(labels))))\n",
    "\n",
    "ax[0].set_title('PCA')\n",
    "ax[1].set_xlabel(inputIndices[0][0]); ax[1].set_ylabel(inputIndices[0][1])\n",
    "ax[1].set_title('Bayesian GPLVM - diag Sep=%.2f' % linearSep(mdiag.X_mean.value, labels))\n",
    "ax[2].set_xlabel(inputIndices[1][0]); ax[2].set_ylabel(inputIndices[1][1])\n",
    "ax[2].set_title('Bayesian GPLVM - full Sep=%.2f' % linearSep(mfull.X_mean.value, labels))\n",
    "for i, c in zip(np.unique(labels), colors):\n",
    "    ax[0].scatter(XPCAplot[labels==i,0], XPCAplot[labels==i,1], color=c, label=i)\n",
    "    ax[1].scatter(mdiag.X_mean.value[labels==i,inputIndices[0][0]],\n",
    "                  mdiag.X_mean.value[labels==i,inputIndices[0][1]], color=c, label=i)\n",
    "    ax[2].scatter(mfull.X_mean.value[labels==i,inputIndices[1][0]], \n",
    "                  mfull.X_mean.value[labels==i,inputIndices[1][1]], color=c, label=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
