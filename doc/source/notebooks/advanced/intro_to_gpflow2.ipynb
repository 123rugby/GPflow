{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPflow with TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gpflow\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import io\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data using TensorFlow Datasets\n",
    "\n",
    "For this example, we create a synthetic dataset (noisy sine function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def noisy_sin(x): \n",
    "    return np.sin(x) + 0.1 * np.random.randn(*x.shape)\n",
    "\n",
    "N, Ntest = 100, 500\n",
    "X, Xtest = np.random.rand(N, 1) * 10, np.random.rand(Ntest, 1) * 10\n",
    "Y, Ytest = noisy_sin(X), noisy_sin(Xtest)\n",
    "\n",
    "plt.plot(X, Y, 'xk')\n",
    "plt.xlim(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Tensorflow Datasets is an efficient way to rapidly shuffle, iterate and batch from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0620 17:38:40.404354 140003769710400 deprecation.py:323] From /home/sergio.diaz/tf2/lib/python3.6/site-packages/tensorflow_core/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((Xtest, Ytest))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "dataset = dataset\\\n",
    "    .repeat(True)\\\n",
    "    .prefetch(10000)\\\n",
    "    .shuffle(buffer_size=10000)\\\n",
    "    .batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a GP model\n",
    "\n",
    "In GPflow2.0, we use tf.Module to build all our models, as well as, their components (kernels, likelihoods, parameters, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10\n",
    "kern = gpflow.kernels.RBF(variance=2.)\n",
    "lik = gpflow.likelihoods.Gaussian()\n",
    "Z = np.linspace(0, 10, M).reshape(-1, 1)\n",
    "\n",
    "model = gpflow.models.SVGP(kernel=kern, likelihood=lik, feature=Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set a module (or a particular parameter) to be non-trainable using the auxiliary method ```set_trainable(module, False)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpflow.utilities.training import set_trainable\n",
    "\n",
    "set_trainable(lik, False)\n",
    "set_trainable(kern.variance, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ```param.assign(value)``` to assign a value to a parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kern.lengthscale.assign(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these changes are reflected when we use ```print_summary(model)``` to print a detailed summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gpflow.utilities.printing import print_summary\n",
    "# print_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using Gradient Tapes\n",
    "\n",
    "In TensorFlow2.0, we can optimise (trainable) model parameters with Tensorflow optimizers using GradientTapes. In this simple example, we perform one gradient update of the Adam optimizer to minimize the negative marginal log likelihood (or ELBO) of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 17:38:43.336522 140003769710400 deprecation.py:323] From /home/sergio.diaz/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:460: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Apply a constraint manually following the optimizer update step.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "with tf.GradientTape() as tape: \n",
    "    tape.watch(model.trainable_variables)\n",
    "    loss = model.neg_log_marginal_likelihood(X, Y)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more elaborare example of a gradient update we can define an ```optimization_step``` that uses decorator ```tf.function``` on a closure. A closure is callable that returns the model objective evaluated at a given dataset when called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Closure: \n",
    "    def set_data(self, batch): \n",
    "        self.X, self.Y = batch\n",
    "        \n",
    "    @tf.function\n",
    "    def __call__(self): \n",
    "        return model.neg_log_marginal_likelihood(self.X, self.Y)\n",
    "\n",
    "closure = Closure()\n",
    "\n",
    "def optimization_step(batch): \n",
    "    closure.set_data(batch)\n",
    "    with tf.GradientTape() as tape: \n",
    "        tape.watch(model.trainable_variables)\n",
    "        loss = closure()\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make use the functionality of TensorFlow Datasets to define a simple training loop that iterates over batches of the training dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_training_loop(model, batch_size, epochs: int):\n",
    "    num_batches_per_epoch = int(N / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        batches_epoch = iter(dataset)\n",
    "        for _ in range(num_batches_per_epoch):\n",
    "            batch = next(batches_epoch)\n",
    "            optimization_step(batch)\n",
    "        if (epoch + 1) % 100 == 0: \n",
    "            print(r'Epoch %i completed: ELBO training set %f4' % (\n",
    "                epoch + 1, model.neg_log_marginal_likelihood(X,Y))\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 17:38:46.466522 140003769710400 ag_logging.py:146] Entity <bound method Dispatcher.dispatch_iter of <dispatched conditional>> appears to be a generator function. It will not be converted by AutoGraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dispatcher.dispatch_iter of <dispatched conditional>> appears to be a generator function. It will not be converted by AutoGraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 17:38:46.905427 140003769710400 ag_logging.py:146] Entity <bound method Dispatcher.dispatch_iter of <dispatched Kuf>> appears to be a generator function. It will not be converted by AutoGraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dispatcher.dispatch_iter of <dispatched Kuf>> appears to be a generator function. It will not be converted by AutoGraph.\n",
      "Epoch 100 completed: ELBO training set 135.8124784\n",
      "Epoch 200 completed: ELBO training set 114.5467354\n",
      "Epoch 300 completed: ELBO training set 109.3089614\n",
      "Epoch 400 completed: ELBO training set 107.8008884\n",
      "Epoch 500 completed: ELBO training set 107.3097194\n",
      "Epoch 600 completed: ELBO training set 107.1252364\n",
      "Epoch 700 completed: ELBO training set 107.0467544\n",
      "Epoch 800 completed: ELBO training set 107.0117884\n",
      "Epoch 900 completed: ELBO training set 106.9966414\n",
      "Epoch 1000 completed: ELBO training set 106.9903464\n"
     ]
    }
   ],
   "source": [
    "simple_training_loop(model, batch_size=batch_size, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring \n",
    "\n",
    "We can monitor the training procedure using TensorFlow summary. First we create a summary writer object under which we can write scalar and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_regression import plotting_regression\n",
    "\n",
    "def summary_matplotlib_image(figures, step, fmt='png'):\n",
    "    for name, fig in figures.items():\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format=fmt, bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        image = tf.image.decode_image(buf.getvalue(), channels=4)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        img_summary = tf.summary.image(name=name, data=image, step=step)\n",
    "\n",
    "def monitored_training_loop(model, batch_size: int, epochs: int, log_dir: str):\n",
    "    summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "    num_batches_per_epoch = int(N / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        batches_epoch = iter(dataset)\n",
    "        for _ in range(num_batches_per_epoch):\n",
    "            batch = next(batches_epoch)\n",
    "            optimization_step(batch)\n",
    "\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', data=model.neg_log_marginal_likelihood(X,Y), step=epoch)\n",
    "            tf.summary.scalar('lik.variance', data=model.likelihood.variance, step=epoch)\n",
    "            tf.summary.scalar('kern.ls', data=model.kernel.lengthscale, step=epoch)\n",
    "            tf.summary.scalar('kern.variance', data=model.kernel.variance, step=epoch)\n",
    "            \n",
    "        if (epoch + 1) % 100 == 0: \n",
    "            print(r'Epoch %i completed: ELBO training set %f4' % (\n",
    "                epoch + 1, model.neg_log_marginal_likelihood(X,Y))\n",
    "                 )    \n",
    "            xx = np.linspace(0, 10, 100).reshape(100, 1) \n",
    "            mean, var = model.predict_f(xx)\n",
    "            samples = model.predict_f_samples(xx, 10)\n",
    "\n",
    "            fig = plotting_regression(X, Y, xx, mean, var, samples)\n",
    "            \n",
    "            with summary_writer.as_default():\n",
    "                summary_matplotlib_image({'samples from model' : fig}, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs folder path: /tmp/logs/20190620-173907\n",
      "Epoch 100 completed: ELBO training set 108.3828024\n",
      "Epoch 200 completed: ELBO training set 107.1631734\n",
      "Epoch 300 completed: ELBO training set 107.0229314\n",
      "Epoch 400 completed: ELBO training set 106.9902964\n",
      "Epoch 500 completed: ELBO training set 106.9803234\n",
      "Epoch 600 completed: ELBO training set 106.9770144\n",
      "Epoch 700 completed: ELBO training set 106.9758394\n",
      "Epoch 800 completed: ELBO training set 106.9753404\n",
      "Epoch 900 completed: ELBO training set 106.9750464\n",
      "Epoch 1000 completed: ELBO training set 106.9748014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = gpflow.models.SVGP(kernel=kern, likelihood=lik, feature=Z)\n",
    "closure = Closure()\n",
    "\n",
    "log_dir = '/tmp/logs/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(r'Logs folder path: %s' % (log_dir))\n",
    "\n",
    "monitored_training_loop(model, batch_size=batch_size, epochs=1000, log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can then use Tensorboard to examine the training procedure more in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! tensorboard --logdir <log directory path>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing: saving and loading models\n",
    "\n",
    "With the help of `tf.train.CheckpointManager` and `tf.train.Checkpoint`, we can checkpoint the model throughout the training procedure. Let's start with a simple example using checkpointing to save and load `tf.Variables`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of variable a: 0.330000\n",
      "Value of variable a: 1.200000\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(1.2)\n",
    "# Create Checkpoint object\n",
    "checkpoint_obj = tf.train.Checkpoint(a=a)\n",
    "checkpoint_path = '/tmp/simple_example/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "manager = tf.train.CheckpointManager(checkpoint_obj, checkpoint_path, max_to_keep=10) \n",
    "# Save variable\n",
    "manager.save()\n",
    "a.assign(0.33)\n",
    "print('Current value of variable a: %f' % (a.numpy()))\n",
    "checkpoint_obj.restore(manager.latest_checkpoint)\n",
    "print('Value of variable a: %f' % (a.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example bellow, we modify a simple training loop to save the model every 100 epochs using the CheckpointManager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gpflow.models.SVGP(kernel=kern, likelihood=lik, feature=Z)\n",
    "closure = Closure()\n",
    "\n",
    "def checkpointing_training_loop(model, batch_size: int, epochs: int, manager: tf.train.CheckpointManager):\n",
    "    num_batches_per_epoch = int(N / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        batches_epoch = iter(dataset)\n",
    "        for _ in range(num_batches_per_epoch):\n",
    "            batch = next(batches_epoch)\n",
    "            optimization_step(batch)\n",
    "        if (epoch + 1) % 100 == 0: \n",
    "            ckpt_path = manager.save()\n",
    "            print(r'Epoch %i completed: ELBO training set %f3, model checkpointing saved at %s' % (\n",
    "                epoch + 1, model.neg_log_marginal_likelihood(X,Y), ckpt_path)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint folder path at: /tmp/tf_ckpts/20190620-1739\n",
      "Epoch 100 completed: ELBO training set 108.2411683, model checkpointing saved at /tmp/tf_ckpts/20190620-1739/ckpt-1\n",
      "Epoch 200 completed: ELBO training set 107.1402743, model checkpointing saved at /tmp/tf_ckpts/20190620-1739/ckpt-2\n",
      "Epoch 300 completed: ELBO training set 107.0170233, model checkpointing saved at /tmp/tf_ckpts/20190620-1739/ckpt-3\n",
      "Epoch 400 completed: ELBO training set 106.9882623, model checkpointing saved at /tmp/tf_ckpts/20190620-1739/ckpt-4\n",
      "Epoch 500 completed: ELBO training set 106.9795233, model checkpointing saved at /tmp/tf_ckpts/20190620-1739/ckpt-5\n",
      "Epoch 600 completed: ELBO training set 106.9766403, model checkpointing saved at /tmp/tf_ckpts/20190620-1739/ckpt-6\n",
      "Epoch 700 completed: ELBO training set 106.9756183, model checkpointing saved at /tmp/tf_ckpts/20190620-1739/ckpt-7\n",
      "Epoch 800 completed: ELBO training set 106.9751813, model checkpointing saved at /tmp/tf_ckpts/20190620-1739/ckpt-8\n",
      "Epoch 900 completed: ELBO training set 106.9749173, model checkpointing saved at /tmp/tf_ckpts/20190620-1739/ckpt-9\n",
      "Epoch 1000 completed: ELBO training set 106.9746913, model checkpointing saved at /tmp/tf_ckpts/20190620-1739/ckpt-10\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "checkpoint_path = '/tmp/tf_ckpts/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)         \n",
    "print(r'Checkpoint folder path at: %s' % (checkpoint_path))\n",
    "\n",
    "checkpointing_training_loop(model, batch_size=batch_size, epochs=1000, manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the models have been saved, we can resore them using ```tf.train.Checkpoint.restore``` and assert their performance corresponds to the logs during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model from epoch 1 : ELBO training set 108.2411683\n",
      "Restored model from epoch 2 : ELBO training set 107.1402743\n",
      "Restored model from epoch 3 : ELBO training set 107.0170233\n",
      "Restored model from epoch 4 : ELBO training set 106.9882623\n",
      "Restored model from epoch 5 : ELBO training set 106.9795233\n",
      "Restored model from epoch 6 : ELBO training set 106.9766403\n",
      "Restored model from epoch 7 : ELBO training set 106.9756183\n",
      "Restored model from epoch 8 : ELBO training set 106.9751813\n",
      "Restored model from epoch 9 : ELBO training set 106.9749173\n",
      "Restored model from epoch 10 : ELBO training set 106.9746913\n"
     ]
    }
   ],
   "source": [
    "for i, recorded_checkpoint in enumerate(manager.checkpoints): \n",
    "    ckpt.restore(recorded_checkpoint)\n",
    "    print(r'Restored model from epoch %i : ELBO training set %f3' % (\n",
    "        i + 1, model.neg_log_marginal_likelihood(X,Y))\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_monitoring",
   "language": "python",
   "name": "tf2_monitoring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
